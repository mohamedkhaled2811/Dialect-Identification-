{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b92f2ad-9cf5-41b5-9727-353e97957e10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     /home/mohamedkhaled/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/mohamedkhaled/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mohamedkhaled/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/mohamedkhaled/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizerFast, Trainer, TrainingArguments, AutoTokenizer, AutoModel\n",
    "from transformers import BertModel, BertTokenizer, get_linear_schedule_with_warmup\n",
    "import seaborn as sns\n",
    "import transformers\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertModel, BertTokenizer, get_linear_schedule_with_warmup,get_cosine_schedule_with_warmup\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from pprint import pprint\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import names\n",
    "import nltk\n",
    "\n",
    "import html\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "import torch\n",
    "from IPython.display import HTML\n",
    "import pyarabic.araby as araby\n",
    "\n",
    "\n",
    "nltk.download('names')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import kornia\n",
    "from  kornia import losses\n",
    "\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from numpy import unique\n",
    "from numpy import where\n",
    "from sklearn.metrics import silhouette_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4e436e4-d198-49bc-8364-e7963d0fe5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = \"/home/mohamedkhaled/Dialect identification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56ced8b8-0b78-4ef1-baeb-30717f28a473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c29506d-8051-46ff-a69c-1d0ca2942467",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ['aubmindlab/bert-large-arabertv02-twitter','UBC-NLP/MARBERTv2']\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name[1])\n",
    "PRE_TRAINED_MODEL_NAME = model_name[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21686eca-a1f9-4bbf-a781-8feaea27bc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data = pd.read_csv(file_dir+'/NADI2023_Release_Train/NADI2023_Release_Train/Subtask1/NADI2023_Subtask1_TRAIN.tsv', sep='\\t')\n",
    "all_dev_data = pd.read_csv(file_dir+'/NADI2023_Release_Train/NADI2023_Release_Train/Subtask1/NADI2023_Subtask1_DEV.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2636a20e-cd33-497e-bec6-e992a20630d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data.rename(columns={'#2_content':'text', '#3_label':'label'}, inplace=True)\n",
    "all_dev_data.rename(columns={'#2_content':'text', '#3_label':'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f7f2b76-ec98-4d7f-b01f-99d0c9d7e77f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#1_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subtask1_train_1</td>\n",
       "      <td>USER روتلج علمود جنسيه</td>\n",
       "      <td>Iraq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subtask1_train_2</td>\n",
       "      <td>النت في عمان يذكرني ببطاقه الافق مال NUM ريالا...</td>\n",
       "      <td>Oman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subtask1_train_3</td>\n",
       "      <td>USER انا كنصراوي لاالوم اخواني النصراويه بتشجي...</td>\n",
       "      <td>Saudi_Arabia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subtask1_train_4</td>\n",
       "      <td>دوله اسرائيل قائمه علي ضعفنا يوم ما نتوحد ونقو...</td>\n",
       "      <td>Palestine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subtask1_train_5</td>\n",
       "      <td>USER لو تقابلنا بعد طول الغياب ضمني ما فيني حي...</td>\n",
       "      <td>Bahrain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>subtask1_train_17996</td>\n",
       "      <td>USER شكد سفله تثمين الخطوات اولاد وين الخدمات ...</td>\n",
       "      <td>Iraq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>subtask1_train_17997</td>\n",
       "      <td>USER القايد صالح راهو يلهي فيك فالعلم والهويه ...</td>\n",
       "      <td>Algeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>subtask1_train_17998</td>\n",
       "      <td>وهسه وينك كالو باخر الدنيا حلم باجر تشوفه جيت ...</td>\n",
       "      <td>Iraq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>subtask1_train_17999</td>\n",
       "      <td>وهو العيد يبقي عيد برده من غير البحر</td>\n",
       "      <td>Egypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>subtask1_train_18000</td>\n",
       "      <td>منو الحيوان الي قاعد يستعرض هالحزه شجوك ي تبن</td>\n",
       "      <td>Kuwait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      #1_id  \\\n",
       "0          subtask1_train_1   \n",
       "1          subtask1_train_2   \n",
       "2          subtask1_train_3   \n",
       "3          subtask1_train_4   \n",
       "4          subtask1_train_5   \n",
       "...                     ...   \n",
       "17995  subtask1_train_17996   \n",
       "17996  subtask1_train_17997   \n",
       "17997  subtask1_train_17998   \n",
       "17998  subtask1_train_17999   \n",
       "17999  subtask1_train_18000   \n",
       "\n",
       "                                                    text         label  \n",
       "0                                 USER روتلج علمود جنسيه          Iraq  \n",
       "1      النت في عمان يذكرني ببطاقه الافق مال NUM ريالا...          Oman  \n",
       "2      USER انا كنصراوي لاالوم اخواني النصراويه بتشجي...  Saudi_Arabia  \n",
       "3      دوله اسرائيل قائمه علي ضعفنا يوم ما نتوحد ونقو...     Palestine  \n",
       "4      USER لو تقابلنا بعد طول الغياب ضمني ما فيني حي...       Bahrain  \n",
       "...                                                  ...           ...  \n",
       "17995  USER شكد سفله تثمين الخطوات اولاد وين الخدمات ...          Iraq  \n",
       "17996  USER القايد صالح راهو يلهي فيك فالعلم والهويه ...       Algeria  \n",
       "17997  وهسه وينك كالو باخر الدنيا حلم باجر تشوفه جيت ...          Iraq  \n",
       "17998               وهو العيد يبقي عيد برده من غير البحر         Egypt  \n",
       "17999      منو الحيوان الي قاعد يستعرض هالحزه شجوك ي تبن        Kuwait  \n",
       "\n",
       "[18000 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62ffd4f3-eda8-470a-b10b-71676d92d5b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#1_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subtask1_dev_1</td>\n",
       "      <td>سشن قيس من الصبح مثل واحد يتريك باجه</td>\n",
       "      <td>Iraq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subtask1_dev_2</td>\n",
       "      <td>امي لماا تناادي بتحكي كل الاسماء يلي بالبيت   ...</td>\n",
       "      <td>Palestine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subtask1_dev_3</td>\n",
       "      <td>باذن الله يتوج هذا العمل الجبار باغلي بطولات ا...</td>\n",
       "      <td>Saudi_Arabia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subtask1_dev_4</td>\n",
       "      <td>USER تريد تساعد عامل النظافه شيل زبالتك يا زبا...</td>\n",
       "      <td>Oman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subtask1_dev_5</td>\n",
       "      <td>شقتلك انا راح تفوزون بالراحه URL</td>\n",
       "      <td>Kuwait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>subtask1_dev_1796</td>\n",
       "      <td>USER فيه راجل ينور وشك وفيه راجل يطفيه URL</td>\n",
       "      <td>Egypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>subtask1_dev_1797</td>\n",
       "      <td>انو شو هو الانجاز يلي ممكن حقق بسنه</td>\n",
       "      <td>Lebanon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>subtask1_dev_1798</td>\n",
       "      <td>USER منت لاقي بشر معصوم غير الرسول خل صدرك شما...</td>\n",
       "      <td>Saudi_Arabia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>subtask1_dev_1799</td>\n",
       "      <td>من تراب لتراب عامڷين حاڷگۉ مصبۉغين بذهب ڷڷيشش ...</td>\n",
       "      <td>Jordan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>subtask1_dev_1800</td>\n",
       "      <td>USER كن العمر حالف ما يزين الا معك</td>\n",
       "      <td>Bahrain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  #1_id                                               text  \\\n",
       "0        subtask1_dev_1               سشن قيس من الصبح مثل واحد يتريك باجه   \n",
       "1        subtask1_dev_2  امي لماا تناادي بتحكي كل الاسماء يلي بالبيت   ...   \n",
       "2        subtask1_dev_3  باذن الله يتوج هذا العمل الجبار باغلي بطولات ا...   \n",
       "3        subtask1_dev_4  USER تريد تساعد عامل النظافه شيل زبالتك يا زبا...   \n",
       "4        subtask1_dev_5                   شقتلك انا راح تفوزون بالراحه URL   \n",
       "...                 ...                                                ...   \n",
       "1795  subtask1_dev_1796         USER فيه راجل ينور وشك وفيه راجل يطفيه URL   \n",
       "1796  subtask1_dev_1797                انو شو هو الانجاز يلي ممكن حقق بسنه   \n",
       "1797  subtask1_dev_1798  USER منت لاقي بشر معصوم غير الرسول خل صدرك شما...   \n",
       "1798  subtask1_dev_1799  من تراب لتراب عامڷين حاڷگۉ مصبۉغين بذهب ڷڷيشش ...   \n",
       "1799  subtask1_dev_1800                 USER كن العمر حالف ما يزين الا معك   \n",
       "\n",
       "             label  \n",
       "0             Iraq  \n",
       "1        Palestine  \n",
       "2     Saudi_Arabia  \n",
       "3             Oman  \n",
       "4           Kuwait  \n",
       "...            ...  \n",
       "1795         Egypt  \n",
       "1796       Lebanon  \n",
       "1797  Saudi_Arabia  \n",
       "1798        Jordan  \n",
       "1799       Bahrain  \n",
       "\n",
       "[1800 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dev_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d27b0aa-28e1-4eb8-90d9-45d6fc501c51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:85: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:92: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:95: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:107: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:85: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:92: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:95: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:107: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/tmp/ipykernel_499417/583215642.py:85: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"([^0-9\\u0621-\\u063A\\u0641-\\u064A\\u0660-\\u0669a-zA-Z\\[\\]])\",\n",
      "/tmp/ipykernel_499417/583215642.py:92: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  \"(\\d+)([\\u0621-\\u063A\\u0641-\\u064A\\u0660-\\u066C]+)\", r\" \\1 \\2 \", text\n",
      "/tmp/ipykernel_499417/583215642.py:95: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  \"([\\u0621-\\u063A\\u0641-\\u064A\\u0660-\\u066C]+)(\\d+)\", r\" \\1 \\2 \", text\n",
      "/tmp/ipykernel_499417/583215642.py:107: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  text = re.sub(\"\\d+\",\"\",text)\n"
     ]
    }
   ],
   "source": [
    "url_regexes = [\n",
    "    r\"(http(s)?:\\/\\/.)?(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)\",\n",
    "    r\"@(https?|ftp)://(-\\.)?([^\\s/?\\.#-]+\\.?)+(/[^\\s]*)?$@iS\",\n",
    "    r\"http[s]?://[a-zA-Z0-9_\\-./~\\?=%&]+\",\n",
    "    r\"www[a-zA-Z0-9_\\-?=%&/.~]+\",\n",
    "    r\"[a-zA-Z]+\\.com\",\n",
    "    r\"(?=http)[^\\s]+\",\n",
    "    r\"(?=www)[^\\s]+\",\n",
    "    r\"://\",\n",
    "]\n",
    "\n",
    "user_mention_regex = r\"@[\\w\\d]+\"\n",
    "email_regexes = [r\"[\\w-]+@([\\w-]+\\.)+[\\w-]+\", r\"\\S+@\\S+\"]\n",
    "redundant_punct_pattern = (\n",
    "    r\"([!\\\"#\\$%\\'\\(\\)\\*\\+,\\.:;\\-<=·>?@\\[\\\\\\]\\^_ـ`{\\|}~—٪’،؟`୍“؛”ۚ【»؛\\s+«–…‘]{2,})\"\n",
    ")\n",
    "regex_tatweel = r\"(\\D)\\1{2,}\"\n",
    "rejected_chars_regex = r\"^[0-9\\a-zA-Z\\[\\]!\\\"#\\$%\\'\\(\\)\\*\\+,\\.:;\\-<=·>?@\\[\\\\\\]\\^_ـ`{\\|}~:—٪’،؟`୍“؛”ۚ»؛\\s+«–…‘]\"\n",
    "\n",
    "regex_url_step1 = r\"(?=http)[^\\s]+\"\n",
    "regex_url_step2 = r\"(?=www)[^\\s]+\"\n",
    "regex_url = r\"(http(s)?:\\/\\/.)?(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)\"\n",
    "regex_mention = r\"@[\\w\\d]+\"\n",
    "regex_email = r\"\\S+@\\S+\"\n",
    "\n",
    "chars_regex = r\"0-9\\u0621-\\u063A\\u0640-\\u066C\\u0671-\\u0674a-zA-Z\\[\\]!\\\"#\\$%\\'\\(\\)\\*\\+,\\.:;\\-<=·>?@\\[\\\\\\]\\^_ـ`{\\|}~—٪’،؟`୍“؛”ۚ»؛\\s+«–…‘\"\n",
    "\n",
    "white_spaced_double_quotation_regex = r'\\\"\\s+([^\"]+)\\s+\\\"'\n",
    "white_spaced_single_quotation_regex = r\"\\'\\s+([^']+)\\s+\\'\"\n",
    "white_spaced_back_quotation_regex = r\"\\`\\s+([^`]+)\\s+\\`\"\n",
    "white_spaced_em_dash = r\"\\—\\s+([^—]+)\\s+\\—\"\n",
    "\n",
    "left_spaced_chars = r\" ([\\]!#\\$%\\),\\.:;\\?}٪’،؟”؛…»·])\"\n",
    "right_spaced_chars = r\"([\\[\\(\\{“«‘*\\~]) \"\n",
    "left_and_right_spaced_chars = r\" ([\\+\\-\\<\\=\\>\\@\\\\\\^\\_\\|\\–]) \"\n",
    "replace_urls_emails_mentions=True\n",
    "strip_tashkeel=True\n",
    "strip_tatweel=True\n",
    "insert_white_spaces=True\n",
    "remove_elongation=True\n",
    "remove_html_markup=True\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "    Preprocess takes an input text line an applies the same preprocessing used in AraBERT\n",
    "                        pretraining\n",
    "    Args:\n",
    "        text (:obj:`str`): inout text string\n",
    "    Returns:\n",
    "        string: A preprocessed string depending on which model was selected\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    text = str(text)\n",
    "    text = html.unescape(text)\n",
    "    if strip_tashkeel:\n",
    "        text = araby.strip_tashkeel(text)\n",
    "    if strip_tatweel:\n",
    "        text = araby.strip_tatweel(text)\n",
    "\n",
    "    if replace_urls_emails_mentions:\n",
    "        # replace all possible URLs\n",
    "        for reg in url_regexes:\n",
    "            text = re.sub(reg, \" رابط \", text)\n",
    "        # REplace Emails with [بريد]\n",
    "        for reg in email_regexes:\n",
    "            text = re.sub(reg, \" بريد \", text)\n",
    "        # replace mentions with [مستخدم]\n",
    "        text = re.sub(user_mention_regex, \"\", text)\n",
    "\n",
    "    if remove_html_markup:\n",
    "        # remove html line breaks\n",
    "        text = re.sub(\"<br />\", \" \", text)\n",
    "        # remove html markup\n",
    "        text = re.sub(\"</?[^>]+>\", \" \", text)\n",
    "\n",
    "    # remove repeated characters >2\n",
    "    if remove_elongation:\n",
    "        text = _remove_elongation(text)\n",
    "\n",
    "    # insert whitespace before and after all non Arabic digits or English Digits and Alphabet and the 2 brackets\n",
    "    if insert_white_spaces:\n",
    "        text = re.sub(\n",
    "            \"([^0-9\\u0621-\\u063A\\u0641-\\u064A\\u0660-\\u0669a-zA-Z\\[\\]])\",\n",
    "            r\" \\1 \",\n",
    "            text,\n",
    "        )\n",
    "\n",
    "        # insert whitespace between words and numbers or numbers and words\n",
    "        text = re.sub(\n",
    "            \"(\\d+)([\\u0621-\\u063A\\u0641-\\u064A\\u0660-\\u066C]+)\", r\" \\1 \\2 \", text\n",
    "        )\n",
    "        text = re.sub(\n",
    "            \"([\\u0621-\\u063A\\u0641-\\u064A\\u0660-\\u066C]+)(\\d+)\", r\" \\1 \\2 \", text\n",
    "        )\n",
    "\n",
    "\n",
    "    text = re.sub(rejected_chars_regex, \"\", text)\n",
    "\n",
    "    # remove extra spaces\n",
    "    # text = _remove_redundant_punct(text)\n",
    "    text = \" \".join(text.replace(\"\\uFE0F\", \"\").split())\n",
    "    text = re.sub('[a-zA-Z|#|<|>|.|||//|:]',\" \",text)\n",
    "    # ALl the other models dont require Farasa Segmentation\n",
    "    text = re.sub(r\"[a-zA-Z]+\", \" \",text)\n",
    "    text = re.sub(\"\\d+\",\"\",text)\n",
    "    text = re.sub(\"[┊┊•°°•´¸•´¨¸•¨¸•]\",\" \",text)\n",
    "    text = re.sub(\"[ŁÀÁÂÃÄÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖØÙÚÛÜÝÞßïîíìëêéèçæåäãâáàðñòóôõöøùúûüýþÿďĎčČċĊĉĈćĆąĄăĂāĀĐđĒēĔĕĖėĘęĚěĜĝĞğįĭĬīĪĩĨħĦĥĤģĢġĠİıĲĳĴĵĶķĸĹĺĻļĽľĿŏŎōŌŋŊŉňņŅńŃłŁŀŐőŒœŔŕŖŗŘřŚśŜŝŞşůŮŭŬūŪũŨŧŦťŤţšŠŰűŲųŴŵŶŷŸŹźŻżŽžſ]\",\" \", text)\n",
    "    text = re.sub(r'[[\\]]+', \" \", text)\n",
    "    text = re.sub(redundant_punct_pattern,\" \", text)\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def _remove_elongation(text):\n",
    "    \"\"\"\n",
    "    :param text:  the input text to remove elongation\n",
    "    :return: delongated text\n",
    "    \"\"\"\n",
    "    # loop over the number of times the regex matched the text\n",
    "    for index_ in range(len(re.findall(regex_tatweel, text))):\n",
    "        elongation = re.search(regex_tatweel, text)\n",
    "        if elongation:\n",
    "            elongation_pattern = elongation.group()\n",
    "            elongation_replacement = elongation_pattern[0]\n",
    "            elongation_pattern = re.escape(elongation_pattern)\n",
    "            text = re.sub(\n",
    "                elongation_pattern, elongation_replacement, text, flags=re.MULTILINE\n",
    "            )\n",
    "        else:\n",
    "            break\n",
    "    return text\n",
    "\n",
    "def _remove_redundant_punct(text):\n",
    "    text_ = text\n",
    "    result = re.search(redundant_punct_pattern, text)\n",
    "    dif = 0\n",
    "    while result:\n",
    "        sub = result.group()\n",
    "        sub = sorted(set(sub), key=sub.index)\n",
    "        sub = \" \" + \"\".join(list(sub)) + \" \"\n",
    "        text = \"\".join(\n",
    "            (text[: result.span()[0] + dif], sub, text[result.span()[1] + dif :])\n",
    "        )\n",
    "        text_ = \"\".join(\n",
    "            (text_[: result.span()[0]], text_[result.span()[1] :])\n",
    "        ).strip()\n",
    "        dif = abs(len(text) - len(text_))\n",
    "        result = re.search(redundant_punct_pattern, text_)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18f63800-9505-4711-a641-68cbadf83051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_499417/583215642.py:104: FutureWarning: Possible set union at position 15\n",
      "  text = re.sub('[a-zA-Z|#|<|>|.|||//|:]',\" \",text)\n",
      "/tmp/ipykernel_499417/583215642.py:104: FutureWarning: Possible set union at position 16\n",
      "  text = re.sub('[a-zA-Z|#|<|>|.|||//|:]',\" \",text)\n",
      "/tmp/ipykernel_499417/583215642.py:110: FutureWarning: Possible nested set at position 1\n",
      "  text = re.sub(r'[[\\]]+', \" \", text)\n"
     ]
    }
   ],
   "source": [
    "all_train_data.text= all_train_data.text.apply(preprocess)\n",
    "all_dev_data.text = all_dev_data.text.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eca53335-fc98-4974-be1c-1794aecc64e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data.text = all_train_data.apply(lambda x : re.sub(r'\"',\"\",x['text']),axis=1)\n",
    "all_dev_data.text = all_dev_data.apply(lambda x : re.sub(r'\"',\"\",x['text']),axis=1)\n",
    "\n",
    "\n",
    "all_train_data.text = all_train_data.apply(lambda x : re.sub(r\"[#]+\",\" هاشتاج \",x['text']),axis=1)\n",
    "all_dev_data.text = all_dev_data.apply(lambda x : re.sub(r\"[#]+\",\" هاشتاج \",x['text']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efc93959-97b6-4571-a041-674b55a94fb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#1_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subtask1_train_1</td>\n",
       "      <td>روتلج علمود جنسيه</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subtask1_train_2</td>\n",
       "      <td>النت في عمان يذكرني ببطاقه الافق مال ريالات نو...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subtask1_train_3</td>\n",
       "      <td>انا كنصراوي لاالوم اخواني النصراويه بتشجيع اور...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subtask1_train_4</td>\n",
       "      <td>دوله اسرائيل قائمه علي ضعفنا يوم ما نتوحد ونقو...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subtask1_train_5</td>\n",
       "      <td>لو تقابلنا بعد طول الغياب ضمني ما فيني حيل اعاتبك</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>subtask1_train_17996</td>\n",
       "      <td>شكد سفله تثمين الخطوات اولاد وين الخدمات وين ا...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>subtask1_train_17997</td>\n",
       "      <td>القايد صالح راهو يلهي فيك فالعلم والهويه الاما...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>subtask1_train_17998</td>\n",
       "      <td>وهسه وينك كالو باخر الدنيا حلم باجر تشوفه جيت ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>subtask1_train_17999</td>\n",
       "      <td>وهو العيد يبقي عيد برده من غير البحر</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>subtask1_train_18000</td>\n",
       "      <td>منو الحيوان الي قاعد يستعرض هالحزه شجوك ي تبن</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      #1_id  \\\n",
       "0          subtask1_train_1   \n",
       "1          subtask1_train_2   \n",
       "2          subtask1_train_3   \n",
       "3          subtask1_train_4   \n",
       "4          subtask1_train_5   \n",
       "...                     ...   \n",
       "17995  subtask1_train_17996   \n",
       "17996  subtask1_train_17997   \n",
       "17997  subtask1_train_17998   \n",
       "17998  subtask1_train_17999   \n",
       "17999  subtask1_train_18000   \n",
       "\n",
       "                                                    text  label  \n",
       "0                                      روتلج علمود جنسيه      9  \n",
       "1      النت في عمان يذكرني ببطاقه الافق مال ريالات نو...      5  \n",
       "2      انا كنصراوي لاالوم اخواني النصراويه بتشجيع اور...      0  \n",
       "3      دوله اسرائيل قائمه علي ضعفنا يوم ما نتوحد ونقو...     10  \n",
       "4      لو تقابلنا بعد طول الغياب ضمني ما فيني حيل اعاتبك      1  \n",
       "...                                                  ...    ...  \n",
       "17995  شكد سفله تثمين الخطوات اولاد وين الخدمات وين ا...      9  \n",
       "17996  القايد صالح راهو يلهي فيك فالعلم والهويه الاما...     16  \n",
       "17997  وهسه وينك كالو باخر الدنيا حلم باجر تشوفه جيت ...      9  \n",
       "17998               وهو العيد يبقي عيد برده من غير البحر     13  \n",
       "17999      منو الحيوان الي قاعد يستعرض هالحزه شجوك ي تبن      3  \n",
       "\n",
       "[18000 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3be765fa-aa9d-4e93-908b-9f5f6f94992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0454e20-8190-4ab5-b00c-06c2c00827bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data.label = all_train_data.label.apply({'Saudi_Arabia':0,'Bahrain':1, 'Qatar':2, 'Kuwait':3, 'UAE':4,\n",
    "                                           'Oman':5, 'Yemen':6, 'Lebanon':7, 'Syria':8,\n",
    "                                           'Iraq':9, 'Palestine':10, 'Jordan':11,\n",
    "                                           'Libya':12, 'Egypt':13, 'Sudan':14, 'Tunisia':15,\n",
    "                                           'Algeria':16, 'Morocco':17}.get)\n",
    "\n",
    "all_dev_data.label = all_dev_data.label.apply({'Saudi_Arabia':0,'Bahrain':1, 'Qatar':2, 'Kuwait':3, 'UAE':4,\n",
    "                                           'Oman':5, 'Yemen':6, 'Lebanon':7, 'Syria':8,\n",
    "                                           'Iraq':9, 'Palestine':10, 'Jordan':11,\n",
    "                                           'Libya':12, 'Egypt':13, 'Sudan':14, 'Tunisia':15,\n",
    "                                           'Algeria':16, 'Morocco':17}.get)\n",
    "\n",
    "class_name = all_train_data.label.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8157987b-2ed8-4693-b747-be811a8b1dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 5, 0, 10, 1, 13, 11, 12, 14, 4, 16, 3, 15, 7, 17, 6, 8, 2]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb78490b-231a-4f5c-b2af-17e407f23db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(\n",
    "  all_train_data,\n",
    "  test_size=0.2,\n",
    "  random_state= np.random.seed(1234),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db3a3b87-da27-4e15-9342-6c3a4029102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_txt =all_train_data['text'][1]\n",
    "tokens = tokenizer.tokenize(sample_txt)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81dd5b9d-a284-4c64-a793-d931659efec8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_txt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m encoding \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[0;32m----> 2\u001b[0m   sample_txt,\n\u001b[1;32m      3\u001b[0m   max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m26\u001b[39m,\n\u001b[1;32m      4\u001b[0m   add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;66;03m# Add '[CLS]' and '[SEP]'\u001b[39;00m\n\u001b[1;32m      5\u001b[0m   return_token_type_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m   pad_to_max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m   return_attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m   return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Return PyTorch tensors,\u001b[39;00m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m encoding\u001b[38;5;241m.\u001b[39mkeys()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_txt' is not defined"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "  sample_txt,\n",
    "  max_length=26,\n",
    "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "  return_token_type_ids=False,\n",
    "  pad_to_max_length=True,\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',  # Return PyTorch tensors,\n",
    ")\n",
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a02918c9-a174-4caa-a1a5-907cd5c5a488",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX LENGTH:  98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_499417/2874467712.py:7: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(token_lens)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "token_lens = []\n",
    "for txt in all_train_data.text:\n",
    "  tokens = tokenizer.encode(txt, max_length=512)\n",
    "  token_lens.append(len(tokens))\n",
    "sns.distplot(token_lens)\n",
    "plt.xlim([0, 220]);\n",
    "plt.xlabel('Token count');\n",
    "print(\"MAX LENGTH: \",max(token_lens))\n",
    "MAX_LEN = max(token_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "236d15e1-e3b9-42db-abb3-7c8f5464f094",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPReviewDataset(Dataset):\n",
    "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
    "    self.reviews = reviews\n",
    "    self.targets = targets\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "  def __len__(self):\n",
    "    return len(self.reviews)\n",
    "  def __getitem__(self, item):\n",
    "    review = str(self.reviews[item])\n",
    "    target = self.targets[item]\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      review,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_len,\n",
    "      return_token_type_ids=False,\n",
    "      pad_to_max_length=True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "    return {\n",
    "      'review_text': review,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "      'targets': torch.tensor(target, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbd7f02f-f11f-48b6-9a80-149d9c155de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Version\n",
    "\n",
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "  ds = GPReviewDataset(\n",
    "    reviews=df.text.to_numpy(),\n",
    "    targets=df.label.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    "  )\n",
    "\n",
    "def create_test_data_loader(df, tokenizer, max_len, batch_size):\n",
    "  ds = GPReviewDataset(\n",
    "    reviews=df.text.to_numpy(),\n",
    "    targets=df.label.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46a5ac9b-ffb6-412a-94d3-15f9260ea612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loader(BATCH_SIZE):\n",
    "\n",
    "  train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "  val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "  test_data_loader = create_test_data_loader(all_dev_data, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "\n",
    "  return train_data_loader,val_data_loader, test_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c428cd34-7f2e-4c2d-b674-65bc00d7e4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SupervisedContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super(SupervisedContrastiveLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        device = features.device\n",
    "        labels = labels.contiguous().view(-1, 1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(device)\n",
    "\n",
    "        anchor_dot_contrast = torch.div(\n",
    "            torch.matmul(features, features.T),\n",
    "            self.temperature\n",
    "        )\n",
    "\n",
    "        # for numerical stability\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "\n",
    "        # mask out self-contrast cases\n",
    "        logits_mask = torch.ones_like(mask) - torch.eye(mask.size(0)).to(device)\n",
    "        mask = mask * logits_mask\n",
    "\n",
    "        # compute log_prob\n",
    "        exp_logits = torch.exp(logits) * logits_mask\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True) + 1e-8)\n",
    "\n",
    "        # compute mean of log-likelihood over positive\n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / (mask.sum(1) + 1e-8)\n",
    "\n",
    "        return -mean_log_prob_pos.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a4afd8f-7b30-4ee1-ab63-42e152888d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "  def __init__(self, n_classes, drop_value):\n",
    "    super(SentimentClassifier, self).__init__()\n",
    "    self.bert = AutoModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "    hidden_size = self.bert.config.hidden_size\n",
    "    self.drop = nn.Dropout(p=drop_value)\n",
    "\n",
    "    # Projection head for contrastive loss\n",
    "    self.projection = nn.Sequential(\n",
    "        nn.Linear(hidden_size, hidden_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_size, 128)  # Reduced dimension for contrastive learning\n",
    "    )\n",
    "\n",
    "    # Classifier head\n",
    "    self.classifier = nn.Sequential(\n",
    "        nn.Linear(hidden_size, hidden_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=drop_value),\n",
    "        nn.Linear(hidden_size, n_classes)\n",
    "    )\n",
    "\n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    outputs = self.bert(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "    \n",
    "    pooled_output = outputs['pooler_output']\n",
    "    dropped = self.drop(pooled_output)\n",
    "\n",
    "    # Get embeddings for contrastive loss\n",
    "    contrastive_features = self.projection(dropped)  # shape: [batch_size, 128]\n",
    "    normed_features = nn.functional.normalize(contrastive_features, dim=1)\n",
    "\n",
    "    # Classification output\n",
    "    logits = self.classifier(dropped)\n",
    "\n",
    "    return logits, normed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f157cf5-6e72-4c79-ab44-7375a7f305a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentClassifier(len(class_name),0.3)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f003cb4-c67e-4003-9586-42d7523b1dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear\n",
    "def optimization(learning_rate,EPOCHS,model,train_data_loader,num_warmup_steps):\n",
    "\n",
    "  optimizer = AdamW(model.parameters(),lr=learning_rate )\n",
    "  total_steps = len(train_data_loader) * EPOCHS\n",
    "  scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps = num_warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    "  )\n",
    "  # loss_fn = nn.CrossEntropyLoss(weight=weights).to(device)\n",
    "  # loss_fn = FocalLoss(alpha=0.5, gamma=2.0, reduction='mean')\n",
    "  # loss_fn = FocalLossLs(alpha=0.5, gamma=2.0, reduction='mean')\n",
    "  # loss_fn = DiceLoss()\n",
    "  # loss_fn = BinaryVSLoss()\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "  # loss_fn = CrossEntropyLoss()\n",
    "  # loss_fn = TverskyLoss(alpha=0.5, beta=0.5)\n",
    "  return optimizer, scheduler, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a8f8a7cb-52c6-4096-a226-fbf9adcf78ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "  model,\n",
    "  data_loader,\n",
    "  ce_loss_fn,\n",
    "  sc_loss_fn,\n",
    "  optimizer,\n",
    "  device,\n",
    "  scheduler,\n",
    "  n_examples,\n",
    "  contrastive_weight=0.5  # You can tune this weight\n",
    "):\n",
    "  model = model.train()\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  for d in data_loader:\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    targets = d[\"targets\"].to(device)\n",
    "\n",
    "    logits, features = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "    _, preds = torch.max(logits, dim=1)\n",
    "\n",
    "    ce_loss = ce_loss_fn(logits, targets)\n",
    "    sc_loss = sc_loss_fn(features, targets)\n",
    "    loss = ce_loss + contrastive_weight * sc_loss\n",
    "\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f60ee98c-d98b-453a-87c3-5a3b7ede3ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def eval_model(model, data_loader, ce_loss_fn, device, n_examples, use_scl=False, scl_loss_fn=None):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "\n",
    "            if isinstance(outputs, tuple):  # expecting logits, embeddings\n",
    "                logits, features = outputs\n",
    "            else:\n",
    "                logits = outputs\n",
    "                features = None\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            ce_loss = ce_loss_fn(logits, targets)\n",
    "\n",
    "            # Optionally include supervised contrastive loss\n",
    "            if use_scl and scl_loss_fn is not None and features is not None:\n",
    "                scl_loss = scl_loss_fn(features, targets)\n",
    "                loss = ce_loss + scl_loss\n",
    "            else:\n",
    "                loss = ce_loss\n",
    "\n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    accuracy = correct_predictions.double() / n_examples\n",
    "    avg_loss = np.mean(losses)\n",
    "    macro_f1 = f1_score(all_targets, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "    return accuracy, avg_loss, macro_f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6001c0c0-1f91-47cc-8717-791cf5ba0eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def run_epochs():\n",
    "  history = defaultdict(list)\n",
    "  best_accuracy = 0\n",
    "\n",
    "  config_defaults = {\n",
    "    'epochs': 10,\n",
    "    'BATCH_SIZE': 8,\n",
    "    'learning_rate': 1e-5,\n",
    "    'dropout': 0.3,\n",
    "    'num_warmup_steps': 5,\n",
    "    'seed': 42,\n",
    "    'contrastive_weight': 0.95  # You can tune this\n",
    "  }\n",
    "\n",
    "  model = SentimentClassifier(len(class_name), config_defaults['dropout'])\n",
    "  model = model.to(device)\n",
    "\n",
    "  train_data_loader, val_data_loader, test_data_loader = create_loader(config_defaults['BATCH_SIZE'])\n",
    "\n",
    "  optimizer, scheduler, _ = optimization(\n",
    "    config_defaults['learning_rate'],\n",
    "    config_defaults['epochs'],\n",
    "    model,\n",
    "    train_data_loader,\n",
    "    config_defaults['num_warmup_steps']\n",
    "  )\n",
    "\n",
    "  # Define both loss functions\n",
    "  ce_loss_fn = nn.CrossEntropyLoss()\n",
    "  sc_loss_fn = SupervisedContrastiveLoss(temperature=0.07)\n",
    "\n",
    "  for epoch in tqdm_notebook(range(config_defaults['epochs'])):\n",
    "    print(f'Epoch {epoch + 1}/{config_defaults[\"epochs\"]}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "      model,\n",
    "      train_data_loader,\n",
    "      ce_loss_fn,\n",
    "      sc_loss_fn,\n",
    "      optimizer,\n",
    "      device,\n",
    "      scheduler,\n",
    "      len(df_train),\n",
    "      contrastive_weight=config_defaults['contrastive_weight']\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss:.4f} accuracy {train_acc:.4f}')\n",
    "\n",
    "    val_acc, val_loss, macro_f1 = eval_model(\n",
    "      model,\n",
    "      val_data_loader,\n",
    "      ce_loss_fn,  # Only use CE loss for evaluation\n",
    "      device,\n",
    "      len(df_val)\n",
    "    )\n",
    "\n",
    "    print(f'Val loss {val_loss:.4f} accuracy {val_acc:.4f} macro-f1 {macro_f1:.4f}')\n",
    "    print()\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "\n",
    "    if val_acc > best_accuracy:\n",
    "      torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "      best_accuracy = val_acc\n",
    "\n",
    "  return model, train_data_loader, val_data_loader, test_data_loader, optimizer, scheduler, ce_loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d5a6628-64f7-4b53-9174-db4d329afd2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_528459/4164718237.py:34: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for epoch in tqdm_notebook(range(config_defaults['epochs'])):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb0308f2f1847bea9e1d2df74e0b2f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 2.5861 accuracy 0.5115\n",
      "Val loss 1.2809 accuracy 0.6967 macro-f1 0.6785\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamedkhaled/anaconda3/envs/ml/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2700: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 1.2231 accuracy 0.7261\n",
      "Val loss 0.7998 accuracy 0.7644 macro-f1 0.7596\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamedkhaled/anaconda3/envs/ml/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2700: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.7480 accuracy 0.8282\n",
      "Val loss 0.7171 accuracy 0.7983 macro-f1 0.7967\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamedkhaled/anaconda3/envs/ml/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2700: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.5135 accuracy 0.8902\n",
      "Val loss 0.7959 accuracy 0.8089 macro-f1 0.8072\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamedkhaled/anaconda3/envs/ml/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2700: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3635 accuracy 0.9317\n",
      "Val loss 0.9944 accuracy 0.8022 macro-f1 0.8010\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamedkhaled/anaconda3/envs/ml/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2700: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.2630 accuracy 0.9568\n",
      "Val loss 1.1348 accuracy 0.8125 macro-f1 0.8106\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamedkhaled/anaconda3/envs/ml/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2700: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.1915 accuracy 0.9742\n",
      "Val loss 1.2747 accuracy 0.8092 macro-f1 0.8089\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamedkhaled/anaconda3/envs/ml/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2700: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.1429 accuracy 0.9827\n",
      "Val loss 1.3264 accuracy 0.8131 macro-f1 0.8124\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamedkhaled/anaconda3/envs/ml/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2700: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.1176 accuracy 0.9874\n",
      "Val loss 1.3399 accuracy 0.8131 macro-f1 0.8120\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamedkhaled/anaconda3/envs/ml/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2700: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.0979 accuracy 0.9908\n",
      "Val loss 1.3639 accuracy 0.8139 macro-f1 0.8132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, train_data_loader, val_data_loader, test_data_loader, optimizer, scheduler, loss_fn = run_epochs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "058d2a2c-96b6-4a94-b3b9-7e8f84099a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628351b8-437c-4896-82cd-0aceb6993282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
